{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell_v1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # forget gate\n",
    "        self.W_if = nn.Linear(input_size, hidden_size)\n",
    "        self.W_hf = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # input gate\n",
    "        self.W_ii = nn.Linear(input_size, hidden_size)\n",
    "        self.W_hi = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_ig = nn.Linear(input_size, hidden_size)\n",
    "        self.W_hg = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # output gate\n",
    "        self.W_io = nn.Linear(input_size, hidden_size)\n",
    "        self.W_ho = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    \n",
    "    def forget_gate(self, x, h):\n",
    "        sum = self.W_if(x) + self.W_hf(h)\n",
    "        return torch.sigmoid(sum)\n",
    "    \n",
    "    def input_gate(self, x, h):\n",
    "        sum_i = self.W_ii(x) + self.W_hi(h)\n",
    "        \n",
    "        return torch.sigmoid(sum_i)\n",
    "    \n",
    "    def gate_gate(self, x, h):\n",
    "        sum_g = self.W_ig(x) + self.W_hg(h)\n",
    "        return torch.tanh(sum_g)\n",
    "\n",
    "    def output_gate(self, x, h):\n",
    "        sum = self.W_io(x) + self.W_ho(h)\n",
    "        return torch.sigmoid(sum)\n",
    "    \n",
    "    def forward(self, x, hx):\n",
    "        \"\"\"\n",
    "        hx[0] = h0 (previous hidden state)\n",
    "        hx[1] = c0 (previous cell state)\n",
    "        \"\"\"\n",
    "        f = self.forget_gate(x, hx[0])\n",
    "\n",
    "        i = self.input_gate(x, hx[0])\n",
    "\n",
    "        g = self.gate_gate(x, hx[0])\n",
    "\n",
    "        c = f * hx[1] + i * g\n",
    "\n",
    "        o = self.output_gate(x, hx[0])\n",
    "\n",
    "        h = o * torch.tanh(c)\n",
    "\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0136,  0.0510], grad_fn=<MulBackward0>),\n",
       " tensor([-0.0877,  0.0929], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = LSTMCell_v1(3, 2)\n",
    "\n",
    "input = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "h0 = torch.zeros(2)\n",
    "c0 = torch.zeros(2)\n",
    "\n",
    "output = cell(input, (h0, c0))\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Cell Efficient Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.W_x = nn.Linear(input_size, 4 * hidden_size) # 4 is for forget, input, gate, and output gate\n",
    "        self.W_h = nn.Linear(hidden_size, 4 * hidden_size)\n",
    "    \n",
    "    def forward(self, x, hx):\n",
    "        assert x.shape[-1] == self.W_x.in_features, \"Input size mismatch\"\n",
    "        assert hx[0].shape[-1] == self.W_x.out_features // 4, \"Output size mismatch\"\n",
    "\n",
    "        gates = self.W_x(x) + self.W_h(hx[0])\n",
    "        f, i, g, o = torch.chunk(gates, 4, dim=-1)\n",
    "        f = torch.sigmoid(f)\n",
    "        i = torch.sigmoid(i)\n",
    "        g = torch.tanh(g)\n",
    "        o = torch.sigmoid(o)\n",
    "\n",
    "        c = f * hx[1] + i * g\n",
    "\n",
    "        h = o * torch.tanh(c)\n",
    "\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1761, 0.0148, 0.4325], grad_fn=<MulBackward0>),\n",
       " tensor([0.7827, 0.1725, 0.5500], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = LSTMCell(5, 3)\n",
    "\n",
    "input = torch.tensor([1., 2., 3., 4., 5.,])\n",
    "\n",
    "h0 = torch.zeros(3)\n",
    "c0 = torch.zeros(3)\n",
    "\n",
    "output = cell(input, (h0, c0))\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1195, -0.2427, -0.9611,  0.5320, -2.3102],\n",
       "         [ 0.4877,  1.0431,  0.8586, -0.3078,  2.6141],\n",
       "         [ 0.2589, -0.9733, -1.6025,  1.4277,  0.6385],\n",
       "         [-0.7495,  0.5077, -0.1007, -0.6688,  0.1554]],\n",
       "\n",
       "        [[ 1.0665,  0.2208,  1.8834, -1.1158, -0.2876],\n",
       "         [ 1.5418, -1.6930, -1.5466, -0.6099, -0.0300],\n",
       "         [ 0.0327, -0.7160,  1.0028,  0.9985,  0.7949],\n",
       "         [-2.0103,  0.2070, -0.9969, -1.3104, -0.7697]],\n",
       "\n",
       "        [[-0.2051,  0.0206, -0.3492,  0.2328,  1.5664],\n",
       "         [ 0.5154,  0.4913, -0.6668, -0.8935, -0.5981],\n",
       "         [ 0.7033, -0.9606,  1.4943,  0.4578, -0.7708],\n",
       "         [ 0.6048, -0.2460,  1.2659,  0.9342, -0.8268]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, 4, 5)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1999, -0.0150, -0.1023],\n",
       "        [-0.1042, -0.0923, -0.0475],\n",
       "        [-0.0583,  0.0196,  0.0155]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = LSTMCell(5, 3)\n",
    "\n",
    "# 3 batch, 4 input_size/sequence_length, 5 emb_size\n",
    "# input = torch.tensor([[1., 2., 3., 4., 5.,], [1., 2., 3., 4., 5.,], [1., 2., 3., 4., 5.,]])\n",
    "input = torch.randn(3, 4, 5)\n",
    "\n",
    "h0 = torch.zeros(3)\n",
    "c0 = torch.zeros(3)\n",
    "\n",
    "ht, ct = cell(input[:,0], (h0, c0))\n",
    "\n",
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1023, -0.0475,  0.0155], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_v1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.0, bidirectional=False, device=None):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "\n",
    "        # create layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "        if self.bidirectional:\n",
    "            self.backward_layers = torch.nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.layers.append(LSTMCell(self.input_size, self.hidden_size))\n",
    "                if self.bidirectional:\n",
    "                    self.backward_layers.append(LSTMCell(self.input_size, self.hidden_size))\n",
    "            else:\n",
    "                self.layers.append(LSTMCell(self.hidden_size, self.hidden_size))\n",
    "                if self.bidirectional:\n",
    "                    self.backward_layers.append(LSTMCell(self.hidden_size, self.hidden_size))\n",
    "            \n",
    "        self.num_layers = num_layers * self.num_directions\n",
    "\n",
    "    def forward(self, x: torch.tensor, h0: tuple[torch.tensor, torch.tensor] = None):\n",
    "        assert x.shape[-1] == self.input_size, \"Input size mismatch\"\n",
    "        if h0 is not None:\n",
    "            assert h0[0].shape[-1] == self.hidden_size, \"Output size mismatch\"\n",
    "\n",
    "        seq_length = x.shape[1]\n",
    "        batch_size = x.shape[0]\n",
    "        if h0 is None:\n",
    "            hx, cx = torch.chunk(torch.zeros(self.num_layers*2, batch_size, self.hidden_size), 2)\n",
    "        else:\n",
    "            hx, cx = h0\n",
    "\n",
    "        # output = torch.tensor([]) # contains all hidden state for the last layer (batch_size, seq_length, hidden_size * D)\n",
    "        h_n = torch.tensor([]) # contains all last hidden state for every layer (num_layers * D, batch_size, hidden_size)\n",
    "        c_n = torch.tensor([])  # contains all last cell state for every layer (num_layers * D, batch_size, hidden_size)\n",
    "        # output_backward = torch.tensor([])\n",
    "        h_n_backward = torch.tensor([])\n",
    "        c_n_backward = torch.tensor([])\n",
    "\n",
    "        input_backward = None\n",
    "        ht_backward = None\n",
    "\n",
    "        \n",
    "        # loop layers\n",
    "        for i in range(len(self.layers)):\n",
    "            next_layer_input = torch.tensor([])\n",
    "\n",
    "            if i == 0:\n",
    "                input = x\n",
    "                if self.bidirectional:\n",
    "                    input_backward = x.flip(dims=(1,))\n",
    "                    next_layer_input_backward = torch.tensor([])\n",
    "            else:\n",
    "                if self.bidirectional:\n",
    "                    next_layer_input_backward = torch.tensor([])\n",
    "                \n",
    "            ht, ct = hx[i], cx[i]\n",
    "            ht_backward, ct_backward = hx[self.num_layers//2+i], cx[self.num_layers//2+i]\n",
    "            for j in range(seq_length):\n",
    "                ht, ct = self.layers[i](input[:,j], (ht,ct)) # take input on [all batch, current seq length]\n",
    "                next_layer_input = torch.cat([next_layer_input, ht.unsqueeze(1)], dim=1)\n",
    "                # hx = ht.clone().detach()\n",
    "\n",
    "                if self.bidirectional:\n",
    "                    # ht_backward, ct_backward = self.backward_layers[i](input_backward[:,j], (ht[i+1],ct[i+1]))\n",
    "                    ht_backward, ct_backward = self.backward_layers[i](input_backward[:,j], (ht_backward,ct_backward))\n",
    "                    next_layer_input_backward = torch.cat([next_layer_input_backward, ht_backward.unsqueeze(1)], dim=1)\n",
    "                    # input_backward = ht_backward\n",
    "            \n",
    "            # append the h_n output of hidden state where n = seq_length on every layer\n",
    "            h_n = torch.cat([h_n, ht.unsqueeze(0)])\n",
    "            c_n = torch.cat([c_n, ct.unsqueeze(0)])\n",
    "            if self.bidirectional:\n",
    "                h_n_backward = torch.cat([h_n_backward, ht_backward.unsqueeze(0)])\n",
    "                c_n_backward = torch.cat([c_n_backward, ct_backward.unsqueeze(0)])\n",
    "\n",
    "            input = next_layer_input.clone().detach()\n",
    "            if self.bidirectional:\n",
    "                input_backward = next_layer_input_backward.clone().detach()\n",
    "\n",
    "        # output = ht\n",
    "        output = next_layer_input.clone().detach()\n",
    "        if ht_backward is not None:\n",
    "            output_backward = next_layer_input_backward.clone().detach()\n",
    "            output = torch.cat([output, output_backward], dim=2)\n",
    "            h_n = torch.cat([h_n, h_n_backward], dim=0)\n",
    "        \n",
    "        assert output.shape == (batch_size, seq_length, self.hidden_size * self.num_directions), \"Output shape mismatch\"\n",
    "        assert h_n.shape == (len(self.layers) * self.num_directions, batch_size, self.hidden_size), \"Hidden state mismatch\"\n",
    "        return output, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 8]), torch.Size([4, 2, 4]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input_size = 6\n",
    "hidden_size = 4\n",
    "num_layers = 2\n",
    "seq_length = 3\n",
    "\n",
    "lstm = LSTM_v1(input_size, hidden_size, num_layers=num_layers, bidirectional=True)\n",
    "inputs = torch.randn(batch_size, seq_length, input_size)\n",
    "# hx = torch.zeros(4)\n",
    "# cx = torch.zeros(4)\n",
    "\n",
    "# output, h_n, c_n = lstm(inputs, (hx, cx))\n",
    "output, h_n, c_n = lstm(inputs)\n",
    "output.shape, h_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output shape should be (batch_size, seq_length, hidden_size * D) -> (2, 3, 4*2) which is true\n",
    "- hidden state shape should be (num_layers * D, batch_size, hidden_size) -> (2*2, 2, 4) which is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_v2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False, device=None):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.layers_backward = None\n",
    "\n",
    "        self.layers_forward = nn.ModuleList([LSTMCell(self.input_size, self.hidden_size) if i == 0 else LSTMCell(self.hidden_size, self.hidden_size) for i in range(num_layers)])\n",
    "        if bidirectional:\n",
    "            self.layers_backward = nn.ModuleList([LSTMCell(self.input_size, self.hidden_size) if i == 0 else LSTMCell(self.hidden_size, self.hidden_size) for i in range(num_layers)])\n",
    "    \n",
    "    def forward(self, x, h0: tuple[torch.tensor, torch.tensor] = None):\n",
    "        assert x.shape[-1] == self.input_size, f\"Input's last shape did not match. Expected ({self.input_size}) but got ({x.shape[-1]}) instead\"\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        seq_length = x.shape[1]\n",
    "\n",
    "        # initialize hx, cx, output\n",
    "        if h0 is None:\n",
    "            hx = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size, device=self.device)\n",
    "            cx = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size, device=self.device)\n",
    "        else:\n",
    "            assert h0[0].shape == (self.num_layers * self.num_directions, batch_size, self.hidden_size), f\"h0 shape did not match. Expected ({self.num_layers * self.num_directions, batch_size, self.hidden_size}) but got ({h0[0].shape}) instead\"\n",
    "            hx, cx = h0[0], h0[1]\n",
    "\n",
    "        output = torch.zeros(batch_size, seq_length, self.hidden_size * self.num_directions, device=self.device)\n",
    "        h_n = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size, device=self.device)\n",
    "        c_n = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size, device=self.device)\n",
    "\n",
    "        # iterate each layer\n",
    "        for layer in range(self.num_layers):\n",
    "            if layer == 0:\n",
    "                input_forward = x\n",
    "                layer_outputs_forward = torch.zeros(batch_size, seq_length, self.hidden_size, device=self.device)\n",
    "                if self.bidirectional:\n",
    "                    input_backward = torch.flip(x, dims=(1,))\n",
    "                    layer_outputs_backward = torch.zeros(batch_size, seq_length, self.hidden_size, device=self.device)\n",
    "\n",
    "            # hidden state start value for each layer\n",
    "            ht_forward = hx[layer]\n",
    "            ct_forward = cx[layer]\n",
    "            if self.bidirectional:\n",
    "                ht_backward = hx[self.num_layers * self.num_directions//2 +layer]\n",
    "                ct_backward = cx[self.num_layers * self.num_directions//2 +layer]\n",
    "            \n",
    "            # iterate each word sequence\n",
    "            for seq in range(seq_length):\n",
    "                # output of each word/cell\n",
    "                ht_forward, ct_forward = self.layers_forward[layer](input_forward[:,seq], (ht_forward,ct_forward)) # (batch_size, hidden_size)\n",
    "\n",
    "                # for every cell output, insert to layer_outputs_forward\n",
    "                layer_outputs_forward[:,seq] = ht_forward\n",
    "\n",
    "                if self.bidirectional:\n",
    "                    ht_backward, ct_backward = self.layers_backward[layer](input_backward[:,seq], (ht_backward, ct_backward))\n",
    "                    layer_outputs_backward[:,seq] = ht_backward\n",
    "\n",
    "            # set current layer output as next layer input\n",
    "            input_forward = layer_outputs_forward.clone().detach()\n",
    "            if self.bidirectional:\n",
    "                input_backward = layer_outputs_backward.clone().detach()\n",
    "                \n",
    "            # save the last value of ht_forward and ct_forward to h_n and c_n\n",
    "            h_n[layer] = ht_forward\n",
    "            c_n[layer] = ct_forward\n",
    "            if self.bidirectional:\n",
    "                h_n[layer+1] = ht_backward\n",
    "                c_n[layer+1] = ct_backward\n",
    "        # output has all hidden states of all sequence on the last layer with shape (batch_size, seq_len, hidden_size * num_directions)\n",
    "        # output = input_forward # input_forward contain all of the hidden states on all sequences on the last layer\n",
    "        output[:, :, :self.hidden_size] = input_forward\n",
    "        if self.bidirectional:\n",
    "            # flip the backward pass\n",
    "            input_backward_aligned = torch.flip(input_backward, dims=(1,))\n",
    "            # output = torch.cat([output, input_backward], dim=-1) # concat the hidden states on backward layer on the last dimension\n",
    "            output[:, :, self.hidden_size:] = input_backward_aligned\n",
    "        \n",
    "        assert output.shape == (batch_size, seq_length, self.hidden_size * self.num_directions), f\"Output shape mismatch. Expected ({(batch_size, seq_length, self.hidden_size * self.num_directions)}) but got ({output.shape}) instead\"\n",
    "        assert h_n.shape == (self.num_layers * self.num_directions, batch_size, self.hidden_size), f\"h_n shape mismatch. Expected ({(self.num_layers * self.num_directions, batch_size, self.hidden_size)}) but got ({h_n.shape}) instead\"\n",
    "        return output, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 8]), torch.Size([4, 2, 4]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input_size = 6\n",
    "hidden_size = 4\n",
    "num_layers = 2\n",
    "seq_length = 3\n",
    "\n",
    "lstm = LSTM_v2(input_size, hidden_size, num_layers=num_layers, bidirectional=True)\n",
    "inputs = torch.randn(batch_size, seq_length, input_size)\n",
    "# hx = torch.zeros(4)\n",
    "# cx = torch.zeros(4)\n",
    "\n",
    "# output, h_n, c_n = lstm(inputs, (hx, cx))\n",
    "output, h_n, c_n = lstm(inputs)\n",
    "output.shape, h_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    # Custom LSTM implementation built from scratch using LSTMCell.\n",
    "    \n",
    "    This implementation supports multiple layers and bidirectional processing.\n",
    "    It processes sequences by applying an LSTM cell at each time step and\n",
    "    propagating the hidden states across layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int, \n",
    "                 num_layers: int = 1, \n",
    "                 bidirectional: bool = False, \n",
    "                 device: Optional[torch.device] = None):\n",
    "        \"\"\"\n",
    "        # Initialize the LSTM module with configurable parameters.\n",
    "        \n",
    "        Args:\n",
    "            input_size: Size of input features\n",
    "            hidden_size: Size of hidden state\n",
    "            num_layers: Number of stacked LSTM layers\n",
    "            bidirectional: Whether to use bidirectional processing\n",
    "            device: Device to place tensors on (CPU/GPU)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.layers_backward = None\n",
    "\n",
    "        # Create forward LSTM layers with appropriate input sizes\n",
    "        self.layers_forward = nn.ModuleList(\n",
    "            [LSTMCell(input_size, hidden_size) if i == 0 \n",
    "             else LSTMCell(hidden_size, hidden_size) \n",
    "             for i in range(num_layers)]\n",
    "        )\n",
    "        \n",
    "        # Create backward LSTM layers if bidirectional\n",
    "        if bidirectional:\n",
    "            self.layers_backward = nn.ModuleList(\n",
    "                [LSTMCell(input_size, hidden_size) if i == 0 \n",
    "                 else LSTMCell(hidden_size, hidden_size) \n",
    "                 for i in range(num_layers)]\n",
    "            )\n",
    "    \n",
    "    def forward(self, \n",
    "                x: torch.Tensor, \n",
    "                h0: Optional[Tuple[torch.Tensor, torch.Tensor]] = None\n",
    "               ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        # Forward pass of the LSTM module.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_length, input_size)\n",
    "            h0: Optional initial hidden state tuple (h, c) of shape \n",
    "                (num_layers * num_directions, batch_size, hidden_size)\n",
    "                \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - output: Tensor of shape (batch_size, seq_length, hidden_size * num_directions)\n",
    "            - h_n: Final hidden state of shape (num_layers * num_directions, batch_size, hidden_size)\n",
    "            - c_n: Final cell state of shape (num_layers * num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        # Note: This implementation manually handles the sequence processing that\n",
    "        # PyTorch's built-in LSTM would do automatically.\n",
    "        \"\"\"\n",
    "        # Validate input dimensions\n",
    "        assert x.shape[-1] == self.input_size, f\"Input's last dimension did not match. Expected ({self.input_size}) but got ({x.shape[-1]}) instead\"\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        seq_length = x.shape[1]\n",
    "\n",
    "        # Initialize hidden and cell states\n",
    "        if h0 is None:\n",
    "            # Create zero tensors for initial states if not provided\n",
    "            hx = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size, device=self.device)\n",
    "            cx = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size, device=self.device)\n",
    "        else:\n",
    "            # Validate provided initial states\n",
    "            assert h0[0].shape == (self.num_layers * self.num_directions, batch_size, self.hidden_size), \\\n",
    "                f\"h0 shape did not match. Expected ({self.num_layers * self.num_directions, batch_size, self.hidden_size}) but got ({h0[0].shape}) instead\"\n",
    "            hx, cx = h0[0], h0[1]\n",
    "\n",
    "        # Pre-allocate output tensors\n",
    "        output = torch.zeros(batch_size, seq_length, self.hidden_size * self.num_directions, device=self.device)\n",
    "        h_n = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size, device=self.device)\n",
    "        c_n = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size, device=self.device)\n",
    "\n",
    "        # Process each layer\n",
    "        for layer in range(self.num_layers):\n",
    "            # Initialize layer-specific variables\n",
    "            if layer == 0:\n",
    "                # For first layer, input is the original sequence\n",
    "                input_forward = x\n",
    "                layer_outputs_forward = torch.zeros(batch_size, seq_length, self.hidden_size, device=self.device)\n",
    "                \n",
    "                if self.bidirectional:\n",
    "                    # For bidirectional, flip the sequence on time dimension\n",
    "                    input_backward = torch.flip(x, dims=(1,))\n",
    "                    layer_outputs_backward = torch.zeros(batch_size, seq_length, self.hidden_size, device=self.device)\n",
    "\n",
    "            # Get initial hidden states for this layer\n",
    "            ht_forward = hx[layer]\n",
    "            ct_forward = cx[layer]\n",
    "            \n",
    "            if self.bidirectional:\n",
    "                # Index calculation for bidirectional hidden states\n",
    "                backward_idx = self.num_layers + layer\n",
    "                ht_backward = hx[backward_idx]\n",
    "                ct_backward = cx[backward_idx]\n",
    "            \n",
    "            # Process each time step in the sequence\n",
    "            for seq in range(seq_length):\n",
    "                # Forward pass for this time step\n",
    "                ht_forward, ct_forward = self.layers_forward[layer](input_forward[:,seq], (ht_forward, ct_forward))\n",
    "                layer_outputs_forward[:,seq] = ht_forward\n",
    "\n",
    "                if self.bidirectional:\n",
    "                    # Backward pass for this time step\n",
    "                    ht_backward, ct_backward = self.layers_backward[layer](input_backward[:,seq], (ht_backward, ct_backward))\n",
    "                    layer_outputs_backward[:,seq] = ht_backward\n",
    "\n",
    "            # Prepare inputs for next layer\n",
    "            # .clone() creates a copy\n",
    "            input_forward = layer_outputs_forward.clone()\n",
    "            \n",
    "            if self.bidirectional:\n",
    "                input_backward = layer_outputs_backward.clone()\n",
    "                \n",
    "            # Store final hidden states for this layer\n",
    "            h_n[layer] = ht_forward\n",
    "            c_n[layer] = ct_forward\n",
    "            \n",
    "            if self.bidirectional:\n",
    "                h_n[backward_idx] = ht_backward\n",
    "                c_n[backward_idx] = ct_backward\n",
    "                \n",
    "        # Combine outputs from forward and backward passes\n",
    "        output[:, :, :self.hidden_size] = input_forward\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            # Flip backward outputs to align with forward sequence\n",
    "            input_backward_aligned = torch.flip(input_backward, dims=(1,))\n",
    "            output[:, :, self.hidden_size:] = input_backward_aligned\n",
    "        \n",
    "        # Validate output shapes\n",
    "        assert output.shape == (batch_size, seq_length, self.hidden_size * self.num_directions), \\\n",
    "            f\"Output shape mismatch. Expected ({batch_size, seq_length, self.hidden_size * self.num_directions}) but got ({output.shape}) instead\"\n",
    "        assert h_n.shape == (self.num_layers * self.num_directions, batch_size, self.hidden_size), \\\n",
    "            f\"h_n shape mismatch. Expected ({self.num_layers * self.num_directions, batch_size, self.hidden_size}) but got ({h_n.shape}) instead\"\n",
    "            \n",
    "        return output, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 8]), torch.Size([4, 2, 4]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input_size = 6\n",
    "hidden_size = 4\n",
    "num_layers = 2\n",
    "seq_length = 3\n",
    "\n",
    "lstm = LSTM_v2(input_size, hidden_size, num_layers=num_layers, bidirectional=True)\n",
    "inputs = torch.randn(batch_size, seq_length, input_size)\n",
    "\n",
    "output, h_n, c_n = lstm(inputs)\n",
    "output.shape, h_n.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
